{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rnn.model import *\n",
    "from rnn.train import *\n",
    "from rnn.predict import *\n",
    "from utils.data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "batch_size = 3\n",
    "sequence_len = 200\n",
    "# Data path\n",
    "rawdata_dir = 'raw_data'\n",
    "middata_dir = 'mid_data'\n",
    "poem_dir = \"poem_result\"\n",
    "model_dir = \"rnn_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gatherer start\n",
      "source read\n",
      "code_book setup start\n",
      "code_book length : 50\n",
      "batch making start\n",
      "number batch making start\n",
      "preprocess done.\n"
     ]
    }
   ],
   "source": [
    "# loda data with preprocessing\n",
    "loader = data_loader(sequence_len, batch_size, rawdata_dir, middata_dir)\n",
    "loader.file_preprocess()\n",
    "loader.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from file\n",
    "# data loader\n",
    "loader = data_loader(sequence_len, batch_size, rawdata_dir, middata_dir)\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Vector Size : 50\n",
      "Total Batch Num : 34830\n",
      "[[[ 4  5  1 ...,  4 16  6]\n",
      "  [12 14  7 ...,  4  9  7]\n",
      "  [ 1  6 20 ..., 13  9 16]]\n",
      "\n",
      " [[ 1  9  7 ...,  5 10 19]\n",
      "  [ 0  3  5 ...,  4 15  6]\n",
      "  [ 0 17  7 ...,  7 18  1]]\n",
      "\n",
      " [[ 0 21  1 ..., 11 26  6]\n",
      "  [ 0  1 19 ...,  0 18  4]\n",
      "  [ 9  0 15 ...,  0 21  9]]\n",
      "\n",
      " ..., \n",
      " [[10  4  5 ...,  5  0  2]\n",
      "  [ 8  1  0 ...,  8  1  5]\n",
      "  [ 0  2  8 ..., 13  5  0]]\n",
      "\n",
      " [[ 3  5 11 ...,  7  5 16]\n",
      "  [12  3  0 ...,  3  6  0]\n",
      "  [ 8  1 20 ..., 21  3  9]]\n",
      "\n",
      " [[ 5 20 12 ...,  0  3  0]\n",
      "  [ 6 22  7 ...,  3 10  0]\n",
      "  [ 3 18 18 ...,  9  7  5]]]\n"
     ]
    }
   ],
   "source": [
    "# load functionality check\n",
    "cb = loader.cb\n",
    "data_batch = loader.np_batchs\n",
    "print(\"Input Vector Size : \" + str(cb.size()))\n",
    "print(\"Total Batch Num : \" + str(len(data_batch)))\n",
    "print(data_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training New Model\n",
    "# Model Params\n",
    "input_size = cb.size()\n",
    "hidden_size = 100\n",
    "output_size = cb.size()\n",
    "n_layers = 1\n",
    "\n",
    "# Model\n",
    "decoder = RNN(input_size, hidden_size, output_size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Exist Model\n",
    "model_name = \"rnn_model_result.pt\"\n",
    "decoder = torch.load(model_dir + \"/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2000 epochs...\n",
      "[Time : 0m 34s, Epoach : (100), Loss : 1.8164]\n",
      "shant's with the was clanded made‚ looks the say the born head;\n",
      "how never the ble she seevition\n",
      "[Time : 1m 8s, Epoach : (200), Loss : 1.6647]\n",
      "eell of a intement were the find of these been and feen he emparble corled‚ about at grove mann\n",
      "[Time : 1m 42s, Epoach : (300), Loss : 1.7206]\n",
      " sended is have geen warming on i manness or she to in eroun take bost of than at the heal is h\n",
      "[Time : 2m 15s, Epoach : (400), Loss : 1.7809]\n",
      " greak blound about its spid\n",
      "\n",
      "and not must and dunce and the gowns real manded‚ and grave\n",
      "\n",
      "and \n",
      "[Time : 2m 50s, Epoach : (500), Loss : 1.7810]\n",
      "three the grand fallant of the chill of thing thoughter mone the court.\n",
      "i . the dirtions the di\n",
      "[Time : 3m 23s, Epoach : (600), Loss : 1.8081]\n",
      "rspunge\n",
      "said‚ he seed sometenty from he live constorthe brayons sachinos‚ while allay into on‚ \n",
      "[Time : 3m 57s, Epoach : (700), Loss : 1.8344]\n",
      "ith they find be triend aven the cleageth of pergober black the throught\n",
      "blewness. teet cry on \n",
      "[Time : 4m 31s, Epoach : (800), Loss : 1.7654]\n",
      "and hart obles\n",
      "digure he drust and many fall the get forestor‚ was the for that well and the de\n",
      "[Time : 5m 4s, Epoach : (900), Loss : 1.5216]\n",
      "t how the hif comprassed the lemmant the else the died sime a could tall to god?\n",
      "crongled i con\n",
      "[Time : 5m 38s, Epoach : (1000), Loss : 1.7611]\n",
      "mpires of the fair red undown\n",
      "1911. everything to could facome‚\n",
      "for a name\n",
      "the spinis the waste\n",
      "[Time : 6m 11s, Epoach : (1100), Loss : 1.8298]\n",
      "can paped up\n",
      "pakes down hell thought unters at the sett hussort the know the violow‚ the reates\n",
      "[Time : 6m 44s, Epoach : (1200), Loss : 1.9161]\n",
      "rcks the sigh.\n",
      "the lafte we like the frill have my leave peat fack with sumpch with street of t\n",
      "[Time : 7m 18s, Epoach : (1300), Loss : 1.9213]\n",
      " through alive man to the brooked‚\n",
      "the shall ways of elu'd my glowas‚\n",
      "and this‚ it over chere‚ \n",
      "[Time : 7m 53s, Epoach : (1400), Loss : 1.8561]\n",
      ".\n",
      "\n",
      "that hearth and fanter out well mand the centern says.\n",
      "\n",
      "the manet\n",
      "when the gurte and breat h\n",
      "[Time : 8m 26s, Epoach : (1500), Loss : 1.7957]\n",
      "was at as seere\n",
      "can my weodless it into the sight\n",
      "whole empt to heading\n",
      "and own hungert a charc\n",
      "[Time : 9m 0s, Epoach : (1600), Loss : 1.7390]\n",
      "bend‚ valom so god\n",
      "that a glass\n",
      "and texcies‚\n",
      "or orman\n",
      "to he constaring the same and to that no \n",
      "[Time : 9m 34s, Epoach : (1700), Loss : 1.6670]\n",
      "m think‚ ahdown.\n",
      "the smovible in the many denery sart covered sloom‚ i rimmanate i do see for h\n",
      "[Time : 10m 8s, Epoach : (1800), Loss : 1.8004]\n",
      "rise\n",
      "and the beneached those head\n",
      "each resend\n",
      "i none dayfice\n",
      "untend in the strift harding to ar\n",
      "[Time : 10m 43s, Epoach : (1900), Loss : 2.1708]\n",
      " the adswash more the words‚\n",
      "callated cuttered thists engual on slows anstersent swaint words w\n",
      "[Time : 11m 17s, Epoach : (2000), Loss : 1.8463]\n",
      "s over how he can have mach hould maining be ignally\n",
      "with mul simpled a turned left me disposin\n",
      "Learning end.. Saving...\n",
      "Saved as ./rnn_models/rnn_model_result.pt\n"
     ]
    }
   ],
   "source": [
    "# Training Script\n",
    "# Hyper Params\n",
    "lr = 0.003\n",
    "n_epochs = -1\n",
    "print_cycle = 1000\n",
    "save_cycle = 10000\n",
    "start_sequence = cb.get_number_batch(\"apple\")\n",
    "\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    if (n_epochs == -1):\n",
    "        epoch = 0\n",
    "        while (True):\n",
    "            epoch += 1\n",
    "            loss = train(decoder, optimizer, criterion, sequence_len, batch_size , *random_training_set(data_batch, sequence_len, batch_size))\n",
    "            \n",
    "            if epoch % print_cycle == 0:\n",
    "                print('[Time : %s, Epoach : (%d), Loss : %.4f]' % (time_since(start), epoch, loss))\n",
    "                print(cb.get_string(predict(decoder, start_sequence, 100)))\n",
    "            if (epoch % save_cycle == 0):\n",
    "                model_num += 1\n",
    "                print(\"Save %d model\" % (model_num))\n",
    "                f = open(\"./\" + poem_dir + \"/poem\" + str(model_num) + \".txt\", 'w')\n",
    "                predicted = predict(decoder, start_sequence, 1000)\n",
    "                f.write(cb.get_string(predicted))\n",
    "                save(decoder, \"./\"+model_dir+\"/rnn_model\"+str(model_num))\n",
    "                f.close()\n",
    "\n",
    "    else :\n",
    "        print(\"Training for %d epochs...\" % n_epochs)\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            loss = train(decoder, optimizer, criterion, sequence_len, batch_size , *random_training_set(data_batch, sequence_len, batch_size))\n",
    "\n",
    "            if epoch % print_cycle == 0:\n",
    "                print('[Time : %s, Epoach : (%d), Loss : %.4f]' % (time_since(start), epoch, loss))\n",
    "                print(cb.get_string(predict(decoder, start_sequence, 100)))\n",
    "\n",
    "        print(\"Learning end.. Saving...\")\n",
    "        f = open(\"./\" + poem_dir + \"/poem_result.txt\", 'w')\n",
    "        predicted = predict(decoder, start_sequence, 1000)\n",
    "        f.write(cb.get_string(predicted))\n",
    "        save(decoder, \"./\"+model_dir+\"/rnn_model_result\")\n",
    "        f.close()\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Saving before quit...\")\n",
    "    save(decoder, \"./\"+model_dir+\"/rnn_model_result\")\n",
    "    \n",
    "except :\n",
    "    print(\"Learning Failure!! Saving before quit...\")\n",
    "    save(decoder, \"./\"+model_dir+\"/rnn_model_result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
